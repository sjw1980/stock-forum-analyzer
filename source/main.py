import requests
import pandas as pd
from bs4 import BeautifulSoup
import time
from datetime import datetime
import os
import pymysql
from sqlalchemy import create_engine, text
import logging
import re
import json
from collections import Counter
import numpy as np
from database import test_database_connection, view_database_contents, get_existing_posts, save_posts_to_db,get_posts_count_from_db, get_db_connection, process_engine
from crawler import crawl_stock_discussion
from sentiment_analyzer import analyze_posts_content

# ë¡œê¹… ì„¤ì • (ë””ë²„ê¹… ëª¨ë“œ)
logging.basicConfig(level=logging.DEBUG, 
                   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


if __name__ == "__main__":
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
    logger.info("=== ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ===")
    if not test_database_connection():
        logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Docker ì»¨í…Œì´ë„ˆê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        exit(1)
    
    # 139480 ì¢…ëª©ì˜ ê²Œì‹œê¸€ ìˆ˜ì§‘
    stock_code = "139480"
    
    # ê¸°ì¡´ ë°ì´í„° í™•ì¸
    logger.info("=== ê¸°ì¡´ ë°ì´í„° í™•ì¸ ===")
    view_database_contents(stock_code, limit=5)
    
    # 1ë‹¨ê³„: ê²Œì‹œê¸€ ëª©ë¡ ìˆ˜ì§‘
    logger.info("=== ê²Œì‹œê¸€ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘ ===")
    existing_set = get_existing_posts(stock_code)
    recent_posts = crawl_stock_discussion(stock_code, start_page=1, end_page=10, existing_set=existing_set)
    keep_continue = True
    
    if not recent_posts.empty:
        logger.info(f"ìˆ˜ì§‘ëœ ê²Œì‹œê¸€ ìˆ˜: {len(recent_posts)}ê°œ")
        # ìˆ˜ì§‘ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        print("\nğŸ“ ìˆ˜ì§‘ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
        for idx, row in recent_posts.head(3).iterrows():
            print(f"  - [{row['ë‚ ì§œ']}] {row['ì œëª©'][:40]}... (ì‘ì„±ì: {row['ì‘ì„±ì']})")
        
        saved_count = save_posts_to_db(recent_posts, stock_code)
        total_count = get_posts_count_from_db(stock_code)
        logger.info(f"ìƒˆë¡œ ìˆ˜ì§‘ëœ ê²Œì‹œê¸€: {saved_count}ê°œ")
        logger.info(f"ì´ ì €ì¥ëœ ê²Œì‹œê¸€: {total_count}ê°œ")
        
        # ì €ì¥ í›„ ë°ì´í„° í™•ì¸
        logger.info("=== ì €ì¥ í›„ ë°ì´í„° í™•ì¸ ===")
        view_database_contents(stock_code, limit=10)
    else:
        logger.info("ìƒˆë¡œìš´ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        # keep_continue = False
    
    if keep_continue:
        # 2ë‹¨ê³„: ê²Œì‹œê¸€ ë³¸ë¬¸ í¬ë¡¤ë§ ë° ë¶„ì„
        logger.info("=== ê²Œì‹œê¸€ ë¶„ì„ ì‹œì‘ ===")
        analyzed_count = analyze_posts_content(stock_code)
        logger.info(f"ë¶„ì„ ì™„ë£Œëœ ê²Œì‹œê¸€: {analyzed_count}ê°œ")
        
        # 3ë‹¨ê³„: ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        logger.info("=== ë¶„ì„ ê²°ê³¼ ìš”ì•½ ===")
        engine = get_db_connection()
        process_engine(engine, stock_code)
        